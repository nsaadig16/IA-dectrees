{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32aeb0d",
   "metadata": {},
   "source": [
    "# Training decision trees\n",
    "\n",
    "Our objective here is to implement the code necessary to train a decision tree.\n",
    "\n",
    "First, we will define some types that will help us to define the signatures of our methods and functions:\n",
    "\n",
    "- A `Value` corresponds to a value in a certain attribute for our domain. It can be numeric (e.g., 3.14) or categorical (e.g., \"blue\").\n",
    "- `Observation` is a list of `Value`s that represent all the values for all the attributes in a real world observation.\n",
    "- `Data` corresponds to a list of observations.\n",
    "- `Labels` is a vector with the labels for our problem. Item in position `i` for this vector (or list) corresponds to the label for observation `i` in our dataset.\n",
    "- `ScoreFn` is a function that takes a list of labels and returns a numeric score measuring the impurity of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809e7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "Value = int | float | str\n",
    "Observation = list[Value]\n",
    "Data = list[Observation]\n",
    "Labels = list[Value]\n",
    "ScoreFn = Callable[[Labels], float]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d1c7d-1900-4782-ba55-cee0e0f24b19",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "First, let's define some functions that can help you in the process of creating our first classification model.\n",
    "\n",
    "For now, just remember that they are here, and when you need them you can come back and implement them. Left as they are, the notebook should run fine until you call them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a62fd6-52a4-4de9-b49f-e149cbb37f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_counts(values: list[Value]) -> dict[Value, int]:\n",
    "    \"\"\"Count how many times each value appears in `values`\"\"\"\n",
    "    return {v : values.count(v) for v in values }\n",
    "\n",
    "def is_numeric(value: Value) -> bool:\n",
    "    \"\"\"Checks if a value is numeric (i.e. a float or an int)\"\"\"\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "def get_query_fn(column: int, value: Value) -> Callable[[Observation], bool]:\n",
    "    \"\"\"\n",
    "    Create a function that separates observations based on a query.\n",
    "    The query can be:\n",
    "\n",
    "    a) categorical: the created function returns true\n",
    "       iff. the observation has the exact value in the column specified.\n",
    "    b) continuous: the created function returns true\n",
    "       iff. the observation has a value smaller than the reference one\n",
    "       in the column specified.\n",
    "\n",
    "    Note: consider any column with a numeric value as continuous.\n",
    "    \"\"\"\n",
    "    if is_numeric(value):\n",
    "        return lambda obs : obs[column] <= value\n",
    "    else:\n",
    "        return lambda obs : obs[column] == value\n",
    "\n",
    "\n",
    "def unique_values(table: list[list[Value]], column_idx: int):\n",
    "    \"\"\"Returns a set of the values in the columns of a table.\"\"\"\n",
    "    return set(table[column_idx])\n",
    "\n",
    "def cast_to(value_str: str) -> Value:\n",
    "    \"\"\"\n",
    "    Given a value represented as a string, try to convert it\n",
    "    to a more specific type (int, float) or fail back to string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(value_str)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return value_str\n",
    "\n",
    "from math import log\n",
    "def log2(x): return log(x) / log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38fc4d",
   "metadata": {},
   "source": [
    "## Representing a decision tree\n",
    "\n",
    "Let's create a class that represents a decision tree.\n",
    "\n",
    "We will use the [dataclasses](https://docs.python.org/3/library/dataclasses.html) module from Python to reduce the boilerplate we need to write for this class.\n",
    "\n",
    "The instances of `Node` will have 5 attributes:\n",
    "\n",
    "- column: The column of the data we are splitting on.\n",
    "- value: The value for this column that we use for splitting the rows.\n",
    "- results: A counter on how many rows we have for each label that reached this node.\n",
    "- true_branch: In case we are in a decision node, the node that an observation reaches if it answers positively to the query of this node.\n",
    "- false_branch: In case we are in a decision node, the node that an observation reaches if it answers negatively to the query of this node.\n",
    "\n",
    "The attributes `column` and `value` define the query we are performing in this decision node. For leaves, those attributes are `None`. We consider queries as seen in the slides, where for continuous columns we perform the query `>= value`, and for categorical columns we perform the query `== value`.\n",
    "\n",
    "The attribute `results` can be defined only on the leaves of the tree.\n",
    "\n",
    "`true_branch` and `false_branch` are `None` for leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "722c75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    column: Optional[int]\n",
    "    value: Optional[Value]\n",
    "    results: Optional[dict[Value, int]]\n",
    "    true_branch: Optional[Node]\n",
    "    false_branch: Optional[Node]\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.true_branch is None\n",
    "    \n",
    "    @classmethod\n",
    "    def new_node(cls, column, value, true_branch, false_branch) -> Node:\n",
    "        \"\"\"Create a new instance of this class representing a decision node.\"\"\"\n",
    "        return cls(column,value,None,true_branch,false_branch)\n",
    "\n",
    "    @classmethod\n",
    "    def new_leaf(cls, labels: Labels) -> Node:\n",
    "        \"\"\"Create a new instance of this class representing a leaf.\"\"\"\n",
    "        results = unique_counts(labels)\n",
    "        return cls(None,None,results,None,None)\n",
    "\n",
    "    def print_tree(self, indent=''):\n",
    "        \"\"\"Prints to stdout a representation of the tree.\"\"\"\n",
    "        # Is this a leaf node?\n",
    "        if self.results!=None:\n",
    "            print(self.results)\n",
    "        else:\n",
    "            # Print the criteria\n",
    "            if is_numeric(self.value): #type:ignore\n",
    "                print(f\"{self.column}: >= {self.value}?\")\n",
    "            else:\n",
    "                print(f\"{self.column}: {self.value}?\")\n",
    "            # Print the branches\n",
    "            print(f\"{indent}T->\", end=\"\")\n",
    "            self.true_branch.print_tree(indent+' ') #type:ignore\n",
    "            print(f\"{indent}F->\", end=\"\")\n",
    "            self.false_branch.print_tree(indent+' ') #type:ignore\n",
    "        \n",
    "    def follow_tree(self, observation: Observation) -> Node:\n",
    "        \"\"\"\n",
    "        Traverse the (sub)tree by answering the queries, until a leaf is reached.\n",
    "        \n",
    "        This method returns the leaf that this observation reaches.\n",
    "        \"\"\"\n",
    "\n",
    "        current = self\n",
    "\n",
    "        while not current.is_leaf():\n",
    "            query = get_query_fn(current.column,current.value)\n",
    "            if query(observation):\n",
    "                current = current.true_branch\n",
    "            else:\n",
    "                current = current.false_branch\n",
    "        return current\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae0fd4",
   "metadata": {},
   "source": [
    "And try a predefined tree with some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee15ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Red?\n",
      "T->{'Grape': 2}\n",
      "F->1: >= 3?\n",
      " T->{'Apple': 2, 'Lemon': 1}\n",
      " F->{'Grape': 1}\n"
     ]
    }
   ],
   "source": [
    "tree = Node.new_node(\n",
    "    0, \"Red\",\n",
    "    Node.new_leaf([\"Grape\", \"Grape\"]),\n",
    "    Node.new_node(\n",
    "        1, 3,\n",
    "        Node.new_leaf([\"Apple\", \"Lemon\", \"Apple\"]),\n",
    "        Node.new_leaf([\"Grape\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b27c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': 2, 'Lemon': 1}\n",
      "{'Apple': 2, 'Lemon': 1}\n",
      "{'Grape': 2}\n",
      "{'Grape': 2}\n",
      "{'Apple': 2, 'Lemon': 1}\n"
     ]
    }
   ],
   "source": [
    "example_data = [\n",
    "    [\"Green\", 3],\n",
    "    [\"Yellow\", 3],\n",
    "    [\"Red\", 1],\n",
    "    [\"Red\", 1],\n",
    "    [\"Yellow\", 2],\n",
    "]\n",
    "\n",
    "for observation in example_data:\n",
    "    print(tree.follow_tree(observation).results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6a872",
   "metadata": {},
   "source": [
    "## Building the tree\n",
    "\n",
    "Defining the trees manually is a tedious process. So, as good engineers, we will automate this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad5491e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iterate_queries(observations : Data) -> Generator[tuple[int, Value],None,None]:\n",
    "    assert len(observations) > 0, \"No data\"\n",
    "\n",
    "    ncols = len(observations[0])\n",
    "    for col in range(0, ncols):\n",
    "        for value in unique_values(observations, col):\n",
    "            yield col, value\n",
    "\n",
    "def recursive_build_tree(scoref: ScoreFn, observations: Data, labels: Labels) -> Node:\n",
    "    if not observations:\n",
    "        return Node.new_leaf([])\n",
    "    root_imp = scoref(labels)\n",
    "    if root_imp == 0:\n",
    "        return Node.new_leaf(labels)\n",
    "    \n",
    "    best_query, best_goodness, best_T, best_F = None, 0, None, None\n",
    "    for col, value in _iterate_queries(observations):\n",
    "        obs_true, labels_true, obs_false, labels_false = divideset(observations, labels, col, value)\n",
    "        root = scoref(labels)\n",
    "        tb = len(obs_true) / len(observations) * scoref(labels_true) \n",
    "        fb = len(obs_false) / len(observations) * scoref(labels_false)\n",
    "        goodness = root - tb - fb\n",
    "                                  \n",
    "        if best_query is None or goodness > best_goodness:\n",
    "                 best_query = col, value\n",
    "                 best_goodness = goodness\n",
    "                 best_T = obs_true, labels_true\n",
    "                 best_F = obs_false, labels_false\n",
    "    return Node.new_node(*best_query, recursive_build_tree(scoref, *best_T), recursive_build_tree(scoref, *best_F))\n",
    "        \n",
    "def divideset(\n",
    "    observations: Data, labels: Labels, column: int, value: Value\n",
    ") -> tuple[Data, Labels, Data, Labels]:\n",
    "    \"\"\"\n",
    "    Divides a set on a specific column.\n",
    "    Can handle numeric or categorical values\n",
    "    \"\"\"                              \n",
    "                                  \n",
    "    query_fn = get_query_fn(column, value)\n",
    "    \n",
    "    observations_true, labels_true, observations_false, labels_false = [], [], [], []\n",
    "\n",
    "    for obv, label in zip(observations, labels):\n",
    "        if query_fn(observation):\n",
    "            observations_true.append(obv)\n",
    "            labels_true.append(label)\n",
    "        else:\n",
    "            observations_false.append(obv)\n",
    "            labels_false.append(label)\n",
    "\n",
    "    return observations_true, labels_true, observations_false, labels_false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99232f4a",
   "metadata": {},
   "source": [
    "### Impurity functions\n",
    "\n",
    "As our building function requires some functions to score the impurity of a node, let's implement the ones that we have seen previously: the gini score and the entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efbe39",
   "metadata": {},
   "source": [
    "Gini score:\n",
    "\n",
    "$$\n",
    "gini(t) = \\sum^{K}_{j_1,j_2 = 1 : j_1 \\ne j_2} p(j_1|t) p(j_2|t) = 1 - \\sum^{K}_{j=1} p(j|t)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc2fb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels: Labels) -> float:\n",
    "    total = len(labels)\n",
    "    results = unique_counts(labels)\n",
    "    probs={ label : count/total for label,count in results.items() }\n",
    "    return 1 - sum(p**2 for p in probs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f3af0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Entropy:\n",
    "\n",
    "$$\n",
    "entropy(t) = -\\sum^{K}_{j=1} p(j|t) log_2(p(j|t))\n",
    "$$\n",
    "\n",
    "**Note** that we are using the $log_2$ function, not $log$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    total = len(labels)\n",
    "    results = unique_counts(labels)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e938c",
   "metadata": {},
   "source": [
    "### Training our first classifier\n",
    "\n",
    "We are ready to build our first tree from some training data:\n",
    "\n",
    "| **Color** | **Size** | **Fruit** |\n",
    "|-----------|----------|-----------|\n",
    "| Green     | 3        | Apple     |\n",
    "| Yellow    | 3        | Apple     |\n",
    "| Red       | 1        | Grape     |\n",
    "| Red       | 2        | Grape     |\n",
    "| Yellow    | 2        | Lemon     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ec293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\"Green\", 3],\n",
    "    [\"Yellow\", 3],\n",
    "    [\"Red\", 1],\n",
    "    [\"Red\", 2],\n",
    "    [\"Yellow\", 2],\n",
    "]\n",
    "\n",
    "labels = [\"Apple\", \"Apple\", \"Grape\", \"Grape\", \"Lemon\"]\n",
    "\n",
    "tree = recursive_build_tree(gini, data, labels)\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37a06b",
   "metadata": {},
   "source": [
    "## Predicting using our decision tree\n",
    "\n",
    "Building the decision tree is interesting but it does not help us in the long term.\n",
    "\n",
    "What we need is some way to predict labels for new observations. Given an observation, we should find which leaf we should consider when deciding the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc1b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in data:\n",
    "    print(observation, \"->\", tree.follow_tree(observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c6235",
   "metadata": {},
   "source": [
    "## A DIY classifier.\n",
    "\n",
    "Finally, we will encapsulate the training and usage of the decision tree in a classs.\n",
    "\n",
    "This class (the machine learning model) can be trained (aka fit) with some data, and then we can use it to classify new observations.\n",
    "\n",
    "Our decision tree model will have 3 different parameters:\n",
    "\n",
    "- Score function: the function that we will use to measure the impurity of the nodes\n",
    "- Beta: the minimum decrease of impurity required to split a node\n",
    "- Prune threshold: the maximum decrease of impurity allowed when prunning a tree\n",
    "\n",
    "The conventions we will follow for this class are:\n",
    "\n",
    "1. The constructor is dummy, and only stores the parameters for our model.\n",
    "2. All the parameters in the constructor must have a default, so we can do `DecisionTreeModel()`.\n",
    "3. The `fit` method can create new attributes on the class, learnt during the training process. We will name those attributes with a final underscore to distinguish them from the parameters set in the constructor. We can use the existence of such attributes to check if the model has been trained.\n",
    "4. The `predict` method must accept multiple observations at once. It should check if the model has been fitted before (e.g. using [hasattr](https://docs.python.org/3.9/library/functions.html?highlight=hasattr#hasattr) over some attribute learnt in `fit`).\n",
    "\n",
    "For convenience, we can add a `score` method to our class. This method will tell us the accuracy of our model on some labelled data. The accuracy of a classifier is the ratio of correctly predicted labels over the total number of observations.\n",
    "\n",
    "\n",
    "\n",
    "**Note:** the conventions follow closely the API defined by the *de facto* standard of Machine Learning in Python: [scikit-learn](https://scikit-learn.org/stable/developers/develop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787059ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Self\n",
    "\n",
    "class DecisionTreeModel:\n",
    "    def __init__(self, scoref: ScoreFn = gini, beta: float = 0, prune_threshold: float = 0):\n",
    "        self.scoref = scoref\n",
    "        self.beta = beta\n",
    "        self.prune_threshold = prune_threshold\n",
    "    \n",
    "    def fit(self, observations: Data, labels: Labels) -> Self:\n",
    "        self.tree_ = ...\n",
    "        return self\n",
    "    \n",
    "    def predict(self, observations: Data) -> Labels:\n",
    "        ...\n",
    "\n",
    "    def score(self, data: Data, labels: Labels) -> float:\n",
    "        predicted = self.predict(data)\n",
    "        correct = sum(\n",
    "            1 if pred == expected else 0\n",
    "            for pred, expected in zip(predicted, labels)\n",
    "        )\n",
    "        return correct / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacec5de",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "We have all the components needed to train decision tress. Despite this, we still have to define our data manually in the code. Ideally, we would load this data from a file, a database, etc.\n",
    "\n",
    "Let's implement a method that reads our training set from a [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) file.\n",
    "\n",
    "As the file we load will have both the observations and the labels, we also want a method that separates those. We will assume for our case that the labels are always the last column of the CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49627059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name: str) -> list[list[Value]]:\n",
    "    table = []\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            ...    \n",
    "    return table\n",
    "\n",
    "\n",
    "def split_observations_and_labels(table: list[list[Value]]) -> tuple[Data, Labels]:\n",
    "    data, labels = [], []\n",
    "    for row in table:\n",
    "        data.append(row[:-1])\n",
    "        labels.append(row[-1])\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb971fe9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Let's load the data from the example in the slides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = split_observations_and_labels(read_csv(\"decision_tree_example.csv\"))\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8c839",
   "metadata": {},
   "source": [
    "And train a decision tree for this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeModel(gini)\n",
    "model.fit(data, labels)\n",
    "\n",
    "model.tree_.print_tree()\n",
    "\n",
    "print(\"The accuracy of our tree in the training set is\", model.score(data, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
